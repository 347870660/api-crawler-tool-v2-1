import requests
import datetime
import time
import os
import webbrowser
import json
import sys
from urllib.parse import urlparse
from typing import Optional, Dict, Any

class APICrawler:
    """APIçˆ¬è™«å·¥å…·ç±»"""
    
    def __init__(self):
        self.visited_today = False
        self.last_save_dir = None
        self.success_count = 0
        self.fail_count = 0
        self.supported_formats = {
            'image': ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'],
            'video': ['mp4', 'avi', 'mov', 'wmv', 'flv', 'mkv'],
            'audio': ['mp3', 'wav', 'flac', 'aac', 'm4a'],
            'text': ['txt', 'json', 'xml', 'html', 'csv']
        }
        
    def print_banner(self):
        """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
        print("=" * 60)
        print("ğŸ•·ï¸  APIçˆ¬è™«å·¥å…· v2.1 - æ•ˆç‡ä¼˜åŒ–ç‰ˆ")
        print("=" * 60)
        print("âœ¨ æ”¯æŒå¤šæ ¼å¼ï¼šå›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ã€æ–‡æœ¬")
        print("ğŸš€ æ™ºèƒ½è¯†åˆ«ï¼šè‡ªåŠ¨æ£€æµ‹å†…å®¹ç±»å‹")
        print("ğŸ“¦ æ‰¹é‡ä¸‹è½½ï¼šæ”¯æŒè¿ç»­ä½œä¸š")
        print("ğŸ›¡ï¸  å®‰å…¨åˆè§„ï¼šå†…ç½®é˜²å°æœºåˆ¶")
        print("âš¡ æ•ˆç‡ä¼˜åŒ–ï¼šæ™ºèƒ½ç›®å½•ç®¡ç† + é«˜é€Ÿä¸‹è½½")
        print("=" * 60)

    def validate_url(self, url: str) -> bool:
        """éªŒè¯URLæ ¼å¼"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False

    def get_content_type(self, response: requests.Response) -> str:
        """æ™ºèƒ½è¯†åˆ«å†…å®¹ç±»å‹"""
        content_type = response.headers.get('Content-Type', '').lower()
        
        # æ ¹æ®Content-Typeåˆ¤æ–­
        if 'text' in content_type or 'json' in content_type or 'xml' in content_type:
            return 'text'
        elif 'image' in content_type:
            return 'image'
        elif 'video' in content_type:
            return 'video'
        elif 'audio' in content_type:
            return 'audio'
        else:
            # æ ¹æ®å†…å®¹ç‰¹å¾åˆ¤æ–­
            content = response.content
            if content.startswith(b'{') or content.startswith(b'['):
                return 'text'  # JSON
            elif content.startswith(b'\x89PNG') or content.startswith(b'\xff\xd8'):
                return 'image'
            elif content.startswith(b'\x00\x00\x00\x20ftyp'):
                return 'video'
            else:
                return 'binary'

    def generate_filename(self, content_type: str, media_type: str = None) -> str:
        """ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        
        if content_type == 'text':
            ext = media_type if media_type in self.supported_formats['text'] else 'txt'
            return f"data_{timestamp}.{ext}"
        elif content_type == 'image':
            ext = media_type if media_type in self.supported_formats['image'] else 'jpg'
            return f"image_{timestamp}.{ext}"
        elif content_type == 'video':
            ext = media_type if media_type in self.supported_formats['video'] else 'mp4'
            return f"video_{timestamp}.{ext}"
        elif content_type == 'audio':
            ext = media_type if media_type in self.supported_formats['audio'] else 'mp3'
            return f"audio_{timestamp}.{ext}"
        else:
            return f"file_{timestamp}.{media_type or 'bin'}"

    def save_content(self, response: requests.Response, save_dir: str, filename: str) -> bool:
        """ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶"""
        try:
            content_type = self.get_content_type(response)
            filepath = os.path.join(save_dir, filename)
            
            if content_type == 'text':
                # ä¿å­˜æ–‡æœ¬å†…å®¹
                content = response.text
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(content)
            else:
                # ä¿å­˜äºŒè¿›åˆ¶å†…å®¹
                content = response.content
                with open(filepath, 'wb') as f:
                    f.write(content)
            
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def crawl_api(self, url: str, count: int, media_type: str, save_dir: str) -> Dict[str, Any]:
        """çˆ¬å–APIæ¥å£ï¼ˆæ•ˆç‡ä¼˜åŒ–ç‰ˆï¼‰"""
        
        # ä¼˜åŒ–è¯·æ±‚å¤´ï¼Œæé«˜æˆåŠŸç‡
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        
        results = {'success': 0, 'failed': 0, 'files': []}
        
        # åˆ›å»ºä¼šè¯ï¼Œæé«˜æ€§èƒ½
        session = requests.Session()
        session.headers.update(headers)
        
        print(f"ğŸš€ å¼€å§‹çˆ¬å– {url}ï¼Œå…± {count} ä¸ªæ–‡ä»¶")
        print("=" * 50)
        
        # æ‰¹é‡å¤„ç†ä¼˜åŒ–
        batch_size = min(10, count)  # æ¯æ‰¹å¤„ç†10ä¸ªæˆ–æ€»æ•°
        success_count = 0
        
        for i in range(count):
            try:
                print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ç¬¬ {i+1}/{count} ä¸ªæ–‡ä»¶...", end='', flush=True)
                
                # ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚ï¼Œæé«˜æ€§èƒ½
                response = session.get(url, timeout=30, allow_redirects=True)
                
                if response.status_code == 200:
                    # ç”Ÿæˆæ–‡ä»¶å
                    filename = self.generate_filename(self.get_content_type(response), media_type)
                    
                    # ä¿å­˜æ–‡ä»¶
                    if self.save_content(response, save_dir, filename):
                        print(f" âœ… æˆåŠŸ - {filename}")
                        results['success'] += 1
                        results['files'].append(filename)
                        success_count += 1
                    else:
                        print(f" âŒ ä¿å­˜å¤±è´¥")
                        results['failed'] += 1
                else:
                    print(f" âŒ è¯·æ±‚å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                    results['failed'] += 1
                
                # æ™ºèƒ½å»¶è¿Ÿç­–ç•¥
                if success_count % batch_size == 0 and success_count > 0:
                    # æ¯æˆåŠŸå¤„ç†ä¸€æ‰¹åï¼Œç¨å¾®å¢åŠ å»¶è¿Ÿ
                    delay = min(2, 0.5 + (success_count // batch_size) * 0.1)
                    time.sleep(delay)
                elif response.status_code != 200:
                    # è¯·æ±‚å¤±è´¥æ—¶å¢åŠ å»¶è¿Ÿ
                    time.sleep(2)
                else:
                    # æ­£å¸¸è¯·æ±‚ä½¿ç”¨è¾ƒçŸ­å»¶è¿Ÿ
                    time.sleep(0.3)
                
            except requests.exceptions.Timeout:
                print(f" âŒ è¯·æ±‚è¶…æ—¶")
                results['failed'] += 1
                time.sleep(3)  # è¶…æ—¶åå¢åŠ å»¶è¿Ÿ
            except requests.exceptions.ConnectionError:
                print(f" âŒ è¿æ¥é”™è¯¯")
                results['failed'] += 1
                time.sleep(5)  # è¿æ¥é”™è¯¯åå¢åŠ å»¶è¿Ÿ
            except requests.exceptions.RequestException as e:
                print(f" âŒ ç½‘ç»œé”™è¯¯: {e}")
                results['failed'] += 1
                time.sleep(2)
            except Exception as e:
                print(f" âŒ æœªçŸ¥é”™è¯¯: {e}")
                results['failed'] += 1
                time.sleep(1)
        
        # å…³é—­ä¼šè¯
        session.close()
        return results

    def get_user_input(self):
        """è·å–ç”¨æˆ·è¾“å…¥ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        print("\nğŸ“ è¯·è¾“å…¥çˆ¬å–å‚æ•°ï¼š")
        
        # è·å–APIæ¥å£åœ°å€
        while True:
            url = input("è¯·è¾“å…¥APIæ¥å£åœ°å€: ").strip()
            if self.validate_url(url):
                break
            print("âŒ æ— æ•ˆçš„URLæ ¼å¼ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
        
        # è·å–çˆ¬å–æ•°é‡
        while True:
            try:
                count = int(input("è¯·è¾“å…¥çˆ¬å–æ•°é‡ (1-1000): "))
                if 1 <= count <= 1000:
                    break
                print("âŒ æ•°é‡å¿…é¡»åœ¨1-1000ä¹‹é—´ï¼")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ï¼")
        
        # è·å–åª’ä½“ç±»å‹
        print("æ”¯æŒçš„æ ¼å¼ï¼š")
        print("  å›¾ç‰‡: jpg, png, gif, bmp, webp")
        print("  è§†é¢‘: mp4, avi, mov, wmv, flv, mkv") 
        print("  éŸ³é¢‘: mp3, wav, flac, aac, m4a")
        print("  æ–‡æœ¬: txt, json, xml, html, csv")
        
        while True:
            media_type = input("è¯·è¾“å…¥åª’ä½“ç±»å‹ (å¦‚: jpg/mp4/mp3/txt): ").strip().lower()
            if media_type:
                break
            print("âŒ åª’ä½“ç±»å‹ä¸èƒ½ä¸ºç©ºï¼")
        
        # æ™ºèƒ½ç›®å½•ç®¡ç†
        save_dir = self.get_save_directory()
        
        return url, count, media_type, save_dir
    
    def get_save_directory(self):
        """æ™ºèƒ½è·å–ä¿å­˜ç›®å½•"""
        # é»˜è®¤ç›®å½•é€‰é¡¹
        default_dirs = [
            os.path.join(os.path.expanduser("~"), "Downloads", "APIçˆ¬è™«"),
            os.path.join(os.path.expanduser("~"), "Desktop", "APIçˆ¬è™«"),
            os.path.join(os.getcwd(), "downloads")
        ]
        
        # å¦‚æœå­˜åœ¨ä¸Šæ¬¡ä½¿ç”¨çš„ç›®å½•ï¼Œä¼˜å…ˆæ˜¾ç¤º
        if self.last_save_dir and os.path.exists(self.last_save_dir):
            print(f"\nğŸ“ æ™ºèƒ½ç›®å½•ç®¡ç†ï¼š")
            print(f"1ï¸âƒ£  ä½¿ç”¨ä¸Šæ¬¡ç›®å½•: {self.last_save_dir}")
            print(f"2ï¸âƒ£  é€‰æ‹©æ–°ç›®å½•")
            print(f"3ï¸âƒ£  ä½¿ç”¨é»˜è®¤ç›®å½•: {default_dirs[0]}")
            
            while True:
                choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
                if choice == '1':
                    return self.last_save_dir
                elif choice == '2':
                    return self.select_new_directory()
                elif choice == '3':
                    save_dir = default_dirs[0]
                    os.makedirs(save_dir, exist_ok=True)
                    return save_dir
                else:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„é€‰æ‹©ï¼")
        else:
            # æ²¡æœ‰ä¸Šæ¬¡ç›®å½•ï¼Œæ˜¾ç¤ºç®€åŒ–é€‰é¡¹
            print(f"\nğŸ“ é€‰æ‹©ä¿å­˜ä½ç½®ï¼š")
            print(f"1ï¸âƒ£  æ¡Œé¢æ–‡ä»¶å¤¹: {default_dirs[1]}")
            print(f"2ï¸âƒ£  ä¸‹è½½æ–‡ä»¶å¤¹: {default_dirs[0]}")
            print(f"3ï¸âƒ£  å½“å‰ç›®å½•: {default_dirs[2]}")
            print(f"4ï¸âƒ£  è‡ªå®šä¹‰ç›®å½•")
            
            while True:
                choice = input("è¯·é€‰æ‹© (1/2/3/4): ").strip()
                if choice in ['1', '2', '3']:
                    save_dir = default_dirs[int(choice) - 1] if choice != '3' else default_dirs[2]
                    os.makedirs(save_dir, exist_ok=True)
                    return save_dir
                elif choice == '4':
                    return self.select_new_directory()
                else:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„é€‰æ‹©ï¼")
    
    def select_new_directory(self):
        """é€‰æ‹©æ–°ç›®å½•"""
        print("\nğŸ“‚ ç›®å½•é€‰æ‹©æç¤ºï¼š")
        print("â€¢ ç›´æ¥è¾“å…¥è·¯å¾„ï¼Œå¦‚: C:\\Users\\Downloads")
        print("â€¢ è¾“å…¥ 'desktop' ä½¿ç”¨æ¡Œé¢ç›®å½•")
        print("â€¢ è¾“å…¥ 'downloads' ä½¿ç”¨ä¸‹è½½ç›®å½•")
        
        save_dir = input("è¯·è¾“å…¥ä¿å­˜ç›®å½•: ").strip()
        
        # å¤„ç†å¿«æ·å‘½ä»¤
        if save_dir.lower() == 'desktop':
            save_dir = os.path.join(os.path.expanduser("~"), "Desktop", "APIçˆ¬è™«")
        elif save_dir.lower() == 'downloads':
            save_dir = os.path.join(os.path.expanduser("~"), "Downloads", "APIçˆ¬è™«")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(save_dir, exist_ok=True)
        return save_dir

def main():
    """ä¸»å‡½æ•°"""
    crawler = APICrawler()
    crawler.print_banner()
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            url, count, media_type, save_dir = crawler.get_user_input()
            
            # åˆ›å»ºä¿å­˜ç›®å½•
            os.makedirs(save_dir, exist_ok=True)
            print(f"ğŸ“ ä¿å­˜ç›®å½•å·²åˆ›å»º: {save_dir}")
            
            # å¼€å§‹çˆ¬å–
            results = crawler.crawl_api(url, count, media_type, save_dir)
            
            # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
            print("\n" + "=" * 50)
            print("ğŸ“Š çˆ¬å–ç»Ÿè®¡ï¼š")
            print(f"âœ… æˆåŠŸ: {results['success']} ä¸ª")
            print(f"âŒ å¤±è´¥: {results['failed']} ä¸ª")
            print(f"ğŸ“ ä¿å­˜ç›®å½•: {save_dir}")
            
            if results['files']:
                print(f"ğŸ“‹ æ–‡ä»¶åˆ—è¡¨: {len(results['files'])} ä¸ªæ–‡ä»¶")
            
            # ä¿å­˜æœ€åä¸€æ¬¡ç›®å½•
            crawler.last_save_dir = save_dir
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        print("\n" + "-" * 30)
        continue_choice = input("æ˜¯å¦ç»§ç»­çˆ¬å–? (y/n): ").strip().lower()
        if continue_choice != 'y':
            break
    
    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨APIçˆ¬è™«å·¥å…·ï¼")
    print("ğŸŒŸ å¦‚æœæœ¬å·¥å…·å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStaræ”¯æŒä¸€ä¸‹ï¼")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–åº“ï¼Œè¯·å…ˆå®‰è£…: pip install requests")
        sys.exit(1)
    
    main()
